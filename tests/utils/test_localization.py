"""–¢–µ—Å—Ç—ã –¥–ª—è –º–æ–¥—É–ª—è utils.localization."""

import pytest
import json
import tempfile
import os
from unittest.mock import patch, MagicMock

from utils.localization import Localization, i18n, _, get_user_locale


@pytest.fixture
def temp_locales_dir():
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Ñ–∞–π–ª–∞–º–∏ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    import tempfile
    import shutil
    
    temp_dir = tempfile.mkdtemp()
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏
    ru_data = {
        "test": {
            "greeting": "–ü—Ä–∏–≤–µ—Ç, {name}!",
            "message": "–¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
            "nested": {
                "deep": "–ì–ª—É–±–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
            }
        }
    }
    
    en_data = {
        "test": {
            "greeting": "Hello, {name}!",
            "message": "Test message",
            "nested": {
                "deep": "Deep value"
            }
        }
    }
    
    with open(os.path.join(temp_dir, 'ru.json'), 'w', encoding='utf-8') as f:
        json.dump(ru_data, f, ensure_ascii=False)
    
    with open(os.path.join(temp_dir, 'en.json'), 'w', encoding='utf-8') as f:
        json.dump(en_data, f, ensure_ascii=False)
    
    yield temp_dir
    
    # –û—á–∏—Å—Ç–∫–∞
    shutil.rmtree(temp_dir)


class TestLocalizationInit:
    """–¢–µ—Å—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    def test_localization_default_init(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        loc = Localization()
        
        assert loc.default_locale == "ru"
        assert isinstance(loc.locales, dict)
    
    def test_localization_custom_locale(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º —è–∑—ã–∫–æ–º."""
        loc = Localization(default_locale="en")
        
        assert loc.default_locale == "en"
    
    @patch('utils.localization.os.path.exists', return_value=False)
    def test_localization_no_locales_dir(self, mock_exists):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–µ–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
        loc = Localization()
        
        # –î–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –æ—à–∏–±–æ–∫
        assert isinstance(loc.locales, dict)
    
    def test_localization_with_temp_dir(self, temp_locales_dir):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        with patch('utils.localization.os.path.join') as mock_join:
            # –ò–º–∏—Ç–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            mock_join.return_value = temp_locales_dir
            
            with patch('utils.localization.os.path.exists', return_value=True):
                with patch('utils.localization.os.listdir', return_value=['ru.json', 'en.json']):
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    loc = Localization()
                    loc._load_locales()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ª–æ–∫–∞–ª–∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å
                    assert len(loc.locales) >= 0  # –ú–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º –∏–∑-–∑–∞ –º–æ–∫–æ–≤


class TestLocalizationGet:
    """–¢–µ—Å—Ç—ã –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫."""
    
    def test_get_simple_key(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∫–ª—é—á–∞."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "test": "–∑–Ω–∞—á–µ–Ω–∏–µ"
            }
        }
        
        result = loc.get("test", "ru")
        assert result == "–∑–Ω–∞—á–µ–Ω–∏–µ"
    
    def test_get_nested_key(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –≤–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –∫–ª—é—á–∞."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "section": {
                    "subsection": {
                        "key": "–≥–ª—É–±–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
                    }
                }
            }
        }
        
        result = loc.get("section.subsection.key", "ru")
        assert result == "–≥–ª—É–±–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
    
    def test_get_with_formatting(self):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "greeting": "–ü—Ä–∏–≤–µ—Ç, {name}!"
            }
        }
        
        result = loc.get("greeting", "ru", name="–ò–≤–∞–Ω")
        assert result == "–ü—Ä–∏–≤–µ—Ç, –ò–≤–∞–Ω!"
    
    def test_get_nonexistent_key(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–ª—é—á–∞."""
        loc = Localization()
        loc.locales = {"ru": {}}
        
        result = loc.get("nonexistent.key", "ru")
        assert result == "nonexistent.key"  # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∞–º –∫–ª—é—á
    
    def test_get_nonexistent_locale(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —è–∑—ã–∫–∞."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "test": "–∑–Ω–∞—á–µ–Ω–∏–µ"
            }
        }
        loc.default_locale = "ru"
        
        result = loc.get("test", "nonexistent")
        assert result == "–∑–Ω–∞—á–µ–Ω–∏–µ"  # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –∏–∑ default_locale
    
    def test_get_default_locale_fallback(self):
        """–¢–µ—Å—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ —è–∑—ã–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "test": "—Ä—É—Å—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
            },
            "en": {}
        }
        loc.default_locale = "ru"
        
        result = loc.get("test", "en")
        assert result == "—Ä—É—Å—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
    
    def test_get_no_default_locale(self):
        """–¢–µ—Å—Ç –±–µ–∑ —è–∑—ã–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        loc = Localization()
        loc.locales = {}
        loc.default_locale = "nonexistent"
        
        result = loc.get("test.key", "any")
        assert result == "test.key"


class TestLocalizationMethods:
    """–¢–µ—Å—Ç—ã –º–µ—Ç–æ–¥–æ–≤ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    def test_get_available_locales(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤."""
        loc = Localization()
        loc.locales = {
            "ru": {},
            "en": {},
            "fr": {}
        }
        
        available = loc.get_available_locales()
        assert set(available) == {"ru", "en", "fr"}
    
    def test_get_available_locales_empty(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —è–∑—ã–∫–æ–≤."""
        loc = Localization()
        loc.locales = {}
        
        available = loc.get_available_locales()
        assert available == []


class TestGlobalFunctions:
    """–¢–µ—Å—Ç—ã –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    @patch('utils.localization.i18n')
    def test_underscore_function(self, mock_i18n):
        """–¢–µ—Å—Ç —Ñ—É–Ω–∫—Ü–∏–∏ _ (underscore)."""
        mock_i18n.get.return_value = "—Ç–µ—Å—Ç–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
        
        result = _("test.key", "ru", name="–¢–µ—Å—Ç")
        
        mock_i18n.get.assert_called_once_with("test.key", "ru", name="–¢–µ—Å—Ç")
        assert result == "—Ç–µ—Å—Ç–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
    
    def test_get_user_locale_default(self):
        """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —è–∑—ã–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)."""
        user_id = 123456
        
        result = get_user_locale(user_id)
        assert result == "ru"  # –ü–æ–∫–∞ –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π


class TestLocalizationErrorHandling:
    """–¢–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    def test_malformed_locale_file(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π JSON —Ñ–∞–π–ª
            malformed_file = os.path.join(temp_dir, 'broken.json')
            with open(malformed_file, 'w') as f:
                f.write("invalid json content")
            
            with patch('utils.localization.os.path.join', return_value=temp_dir):
                with patch('utils.localization.os.path.exists', return_value=True):
                    with patch('utils.localization.os.listdir', return_value=['broken.json']):
                        loc = Localization()
                        loc._load_locales()
                        
                        # –ù–µ –¥–æ–ª–∂–Ω–æ –ø–∞–¥–∞—Ç—å, –¥–æ–ª–∂–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É
                        assert isinstance(loc.locales, dict)
    
    def test_get_with_type_error(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–∫–∏ —Ç–∏–ø–æ–≤ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "test": {"not": "a string"}  # –ù–µ —Å—Ç—Ä–æ–∫–∞
            }
        }
        
        result = loc.get("test", "ru")
        # –î–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        assert isinstance(result, str)
    
    def test_get_with_key_error_in_nested(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–∫–∏ –∫–ª—é—á–∞ –≤–æ –≤–ª–æ–∂–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "level1": {
                    "level2": "value"
                }
            }
        }
        
        result = loc.get("level1.nonexistent.level3", "ru")
        assert result == "level1.nonexistent.level3"


class TestLocalizationIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    def test_real_locales_structure(self):
        """–¢–µ—Å—Ç —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç
        assert isinstance(i18n, Localization)
        assert i18n.default_locale == "ru"
    
    def test_bot_messages_localization(self):
        """–¢–µ—Å—Ç –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –±–æ—Ç–∞."""
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º, —á—Ç–æ –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –±–æ—Ç–∞
        loc = Localization()
        loc.locales = {
            "ru": {
                "bot": {
                    "welcome": {
                        "greeting": "–ü—Ä–∏–≤–µ—Ç, {name}!"
                    },
                    "errors": {
                        "general": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞"
                    }
                }
            }
        }
        
        greeting = loc.get("bot.welcome.greeting", "ru", name="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å")
        error = loc.get("bot.errors.general", "ru")
        
        assert greeting == "–ü—Ä–∏–≤–µ—Ç, –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å!"
        assert error == "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞"
    
    def test_multilingual_support(self):
        """–¢–µ—Å—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —è–∑—ã–∫–æ–≤."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "message": "–†—É—Å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"
            },
            "en": {
                "message": "English message"
            }
        }
        
        ru_msg = loc.get("message", "ru")
        en_msg = loc.get("message", "en")
        
        assert ru_msg == "–†—É—Å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"
        assert en_msg == "English message"


class TestLocalizationPerformance:
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    def test_multiple_get_calls(self):
        """–¢–µ—Å—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ get."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "test": "–∑–Ω–∞—á–µ–Ω–∏–µ {number}"
            }
        }
        
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –≤—ã–∑—ã–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º
        for i in range(100):
            result = loc.get("test", "ru", number=i)
            assert result == f"–∑–Ω–∞—á–µ–Ω–∏–µ {i}"
    
    def test_large_localization_data(self):
        """–¢–µ—Å—Ç —Å –±–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º –¥–∞–Ω–Ω—ã—Ö –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
        loc = Localization()
        
        # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        large_data = {}
        for i in range(100):
            large_data[f"section_{i}"] = {
                f"key_{j}": f"value_{i}_{j}" for j in range(50)
            }
        
        loc.locales = {"ru": large_data}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è
        result = loc.get("section_50.key_25", "ru")
        assert result == "value_50_25"


class TestLocalizationEdgeCases:
    """–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏."""
    
    def test_empty_key(self):
        """–¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º –∫–ª—é—á–æ–º."""
        loc = Localization()
        loc.locales = {"ru": {"": "–ø—É—Å—Ç–æ–π –∫–ª—é—á"}}
        
        result = loc.get("", "ru")
        assert result == "–ø—É—Å—Ç–æ–π –∫–ª—é—á"
    
    def test_key_with_dots_in_value(self):
        """–¢–µ—Å—Ç –∫–ª—é—á–∞ —Å —Ç–æ—á–∫–∞–º–∏ –≤ –∑–Ω–∞—á–µ–Ω–∏–∏."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "test": "–∑–Ω–∞—á–µ–Ω–∏–µ.—Å.—Ç–æ—á–∫–∞–º–∏"
            }
        }
        
        result = loc.get("test", "ru")
        assert result == "–∑–Ω–∞—á–µ–Ω–∏–µ.—Å.—Ç–æ—á–∫–∞–º–∏"
    
    def test_unicode_keys_and_values(self):
        """–¢–µ—Å—Ç —Å Unicode –∫–ª—é—á–∞–º–∏ –∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏."""
        loc = Localization()
        loc.locales = {
            "ru": {
                "—Ç–µ—Å—Ç": "—Ä—É—Å—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å —ç–º–æ–¥–∑–∏ üéâ",
                "emoji_key_üî•": "–∑–Ω–∞—á–µ–Ω–∏–µ —Å —ç–º–æ–¥–∑–∏ –∫–ª—é—á–æ–º"
            }
        }
        
        result1 = loc.get("—Ç–µ—Å—Ç", "ru")
        result2 = loc.get("emoji_key_üî•", "ru")
        
        assert result1 == "—Ä—É—Å—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å —ç–º–æ–¥–∑–∏ üéâ"
        assert result2 == "–∑–Ω–∞—á–µ–Ω–∏–µ —Å —ç–º–æ–¥–∑–∏ –∫–ª—é—á–æ–º"
    
    def test_very_deep_nesting(self):
        """–¢–µ—Å—Ç –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–æ–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏."""
        loc = Localization()
        
        # –°–æ–∑–¥–∞–µ–º –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        deep_data = {"level1": {"level2": {"level3": {"level4": {"level5": "–≥–ª—É–±–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"}}}}}
        loc.locales = {"ru": deep_data}
        
        result = loc.get("level1.level2.level3.level4.level5", "ru")
        assert result == "–≥–ª—É–±–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
